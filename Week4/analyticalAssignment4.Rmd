---
title: "Week 4 Analytical Assigment"
author: "M. Onimus"
date: "04/2/2020"
output:
  html_document:
    code_folding: show
    toc: yes
    toc_depth: 3
    toc_float:
      collapse: yes
      smooth_scrolling: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(haven)
library(rstatix)
library(table1)
library(kableExtra)
library(MatchIt)
# library(car)
# library(broom)
# library(oddsratio)
# library(jtools)

# library(nnet)
# library(MASS)

```

# R Set up

Before getting started, I have loaded in a few packages to help us with the analysis.

-   `tidyverse`: A collection of r packages used to make data import, manipulation, and analysis easier.
-   `here`: A package that makes it easier to navigate around the folder structure.
-   `haven`: A package with a set of functions for reading in SAS files.
-   `rstatix`: A package to quickly calculate ttest between variables
-   `kableExtra`: A package for printing pretty tables to html.
-   `table1`: A package that allows for creation of table 1's with relative ease
-   `MatchIt`: A package used to create PSM


# From the Assignment

## Introduction

In this week’s analytic assignment, you will compare a group of patients who received and did not receive a treatment. The first comparison will be of the entire population of patients, then you will build a logistic regression model, save the predicted scores and generate a matched cohort of treated and non-treated patients. You will then compare the groups after matching and comment on the balance between the matched cohorts.

For the multinomial assignment you will use the data set Health2_PSM, which has the following variables:

-   subject - Unique observation identifier
-   treatment - 1=received the treatment; 0=did not receive the treatment
-   SEX - 1=patient was male; 0=patient was female
-   AGE - age in years
-   AGE_SQ - age squared (age*age)
-   urban_rural: live in an urban or non-urban (rural, or suburban) zip code
-   unemp_rate: unemployment rate in the subject's zip code
-   med_hh_income: median household income in the subject's zip code
-   disease_burden_bsln: general score of disease states at baseline - higher scores indicate higher illness burden
-   disease_burden_obs: general score of disease states post intervention - higher scores indicate higher illness burden

-   ALZ: had diagnosis of Alzheimer’s (yes=1, no=0)
-   AST: had diagnosis of asthma (yes=1, no=0)
-   CAD: had diagnosis of coronary artery disease (yes=1, no=0)
-   CHF: had diagnosis of congestive heart failure (yes=1, no=0)
-   COPD: had diagnosis of chronic obstructive pulmonary disease (yes=1, no=0)
-   DIAB: had diagnosis of diabetes (yes=1, no=0)
-   HTN: had diagnosis of hypertension (yes=1, no=0)
-   OSTEO: had diagnosis of osteoarthritis (yes=1, no=0)

-   PCP_cost_PMPM: baseline medical costs associated with Primary Care Physician (PCP) visits 
-   IP_cost_PMPM: baseline medical costs associated with acute inpatient admissions
-   ER_cost_PMPM: baseline medical cost associated with Emergency Room visits
-   total_cost_pmpm_pre: total medical costs in the baseline, or pre period.
-   total_cost_pmpm_post: total medical costs post intervention
-   ER_visits_pmpm: number of ER visits in the baseline period
-   PCP_visits_pmpm: number of PCP visits in the baseline period
-   IP_admits_pmpm: number of inpatient admissions in the baseline period
-   ER_Flag: 1=had at least 1 ER visit in the baseline period; 0=did not have an ER visit
-   PCP_Flag: 1=had at least 1 PCP visit in the baseline period; 0=did not have a PCP visit
-   IP_Flag: 1=had at least 1 inpatient admission visit in the baseline period; 0=did not have an inpatient admission visit

Note: PMPM refers to Per Member Per Month - an aggregate of the cost (or utilization) over a 12-month period divided by 12 to give an average per month for each person. In some contexts, observations for some patients may be observed over differing lengths of time so computing a measure on a per-month basis allow comparisons to be made between patients with different lengths of observation.

# Assignment Start

## Read the data in

In order to read the data into R, we will need to use the `haven` package.

```{r readData}

multi <- read_sas(here("data/health2_psm.sas7bdat"))


```

This data set contains `r NROW(multi)` rows with `r NCOL(multi)` variables, as described in the data overview.

## Question 1

Compare the treatment group to the pool of potential comparison group observations using t-tests (PROC TTEST) and chi-square tests (PROC FREQ). 

The first thing we will do is to create the Table 1 as would typically appear in a journal article.  Of course we could clean the labels up and make this considerably more presentable but for this assignment, this output seems suitable.

```{r table1}

# below code borrowed from: https://cran.r-project.org/web/packages/table1/vignettes/table1-examples.html

pvalue <- function(x, ...) {
    # Construct vectors of data y, and groups (strata) g
    y <- unlist(x)
    g <- factor(rep(1:length(x), times=sapply(x, length)))
    if (is.numeric(y)) {
        # For numeric variables, perform a standard 2-sample t-test
        p <- t.test(y ~ g)$p.value
    } else {
        # For categorical variables, perform a chi-squared test of independence
        p <- chisq.test(table(y, g))$p.value
    }
    # Format the p-value, using an HTML entity for the less-than sign.
    # The initial empty string places the output on the line below the variable label.
    c("", sub("<", "&lt;", format.pval(p, digits=3, eps=0.001)))
}


tableClean <- multi %>% 
  mutate(treatment = factor(treatment, levels = c(0,1), labels = c("No Treatment", "Treatment")))

table1(~ AGE + med_HH_income + unemp_rate + disease_burden_bsln + disease_burden_obs + 
         PCP_cost_PMPM + IP_cost_PMPM + ER_cost_PMPM + total_cost_pmpm_pre + 
         total_cost_pmpm_post + ER_visits_pmpm + PCP_visits_pmpm + IP_admits_pmpm + factor(SEX) + factor(urban_rural) + factor(ALZ) + factor(AST) + factor(CAD)
       + factor(CHF) + factor(COPD) + factor(DIAB) + factor(HTN) + factor(OSTEO)
        + factor(ER_Flag) + factor(PCP_Flag) + factor(IP_Flag) | treatment, data = tableClean,
       overall = F, extra.col = list('P-value'=pvalue))


```

The table presented above is for the overall sample.  While a number of variables were considered statistically significant (17), only a few may be practically significant.  For example, the no treatment group had a mean age of 43 compared with the treatment group mean age of 44.3, this difference may be statistically significant but is probably not practically significant.  However, median household income for the treatment group is ~$10,000 more, this may have practical impact on the treatment results.  The zip code between the no treatment and treatment group may also be practically significant.  Overall, the number of chronic conditions between the two sample groups seem pretty similar.



## Question 2

Run a logistic regression model (PROC LOGISTIC) and save the propensity score outputs. Then compare the propensity score overlap visually using PROC UNIVARIATE.

First, we need to build the logistic model.

```{r logit}

logit <- glm(treatment ~ total_cost_pmpm_pre + AGE + SEX + ALZ + 
               AST + CAD + CHF + COPD + DIAB + HTN + OSTEO + 
               disease_burden_bsln, family = binomial(link='logit'), data = multi)

summary(logit)


```

Once we have the model built, we need to go back and create the propensity scores.

```{r calcPSM}

ps <- tibble(score = predict(logit, type = 'response'),
             actual = multi$treatment)

psSummmary <- ps %>% 
  group_by(actual) %>% 
  summarise(mean = mean(score))

ggplot(ps, aes(x = score, fill = as.factor(actual))) +
  geom_histogram(aes(y = ..density.., position = 'identity'), binwidth = 0.005) +
  theme_classic()


```

The mean score of no treatment group was 0.302 and the mean score of the treatment group was 0.307.

The shape of each treatment group is very similar with slight tailing.  It is clear that the model is skewed to prediction 0 and not 1 based upon where the mean of the data is and the location of the peak of the histogram.

Looking at the ROC curve (from the SAS model), it is very close to 0.5 meaning that the model is going not better than random chance.  Since most of the sample is in the 0 treatment group, it would make sense that it would put most of the predictions closer to 0 than 1.

## Question 3

Run PROC PSMATCH to match the treatment and controls and examine the distribution of propensity scores.

To do the propensity score matching, I will be using the `MatchIt` package (this is my first time using the package).  From reading about the packages, I need to make sure there are no NAs in the data first (there are not any) and then provide a formula and method.  I choose the nearest method here which is a 1:1 nearest neighbor without replacement with a distance estimate from the logisitic regression.

```{r psmatch}

set.seed(2)

multiMatch <- matchit(treatment ~ total_cost_pmpm_pre + AGE + SEX + ALZ + 
               AST + CAD + CHF + COPD + DIAB + HTN + OSTEO + 
               disease_burden_bsln, data = multi, method = 'nearest',
               caliper = 0.02)

summary(multiMatch)

matchedData <- match.data(multiMatch)

matchedDatamin <- min(matchedData$distance)
matchedDatamax <- max(matchedData$distance)


```

The nearest algorithm in R with a caliper of 0.02 matched 24,519 pairs.  The SAS algorithm matched 24,516 pairs.  

The nearest algorithm in R did not match 33 in the treatment group to the control.  The SAS algorithm did not match 36.

The min score matched was `r matchedDatamin` and the max score matched was `r matchedDatamax`.

```{r matchedPlot1}

ggplot(matchedData, aes(x = distance, fill = as.factor(treatment))) +
 geom_histogram(position = 'identity') +
  facet_grid(rows = vars(treatment)) +
  theme_classic()


```

## Question 4

Change the caliper to 0.01 and re-run the analyses.


```{r psmatch2}

multiMatch2 <- matchit(treatment ~ total_cost_pmpm_pre + AGE + SEX + ALZ + 
               AST + CAD + CHF + COPD + DIAB + HTN + OSTEO + 
               disease_burden_bsln, data = multi, method = 'nearest',
               caliper = 0.01)

summary(multiMatch2)

matchedData2 <- match.data(multiMatch2)

matchedDatamin2 <- min(matchedData2$distance)
matchedDatamax2 <- max(matchedData2$distance)


```

The nearest algorithm in R with a caliper of 0.01 matched 24,486 pairs.  The SAS algorithm matched 24,467 pairs.  

The nearest algorithm in R did not match 66 in the treatment group to the control.  The SAS algorithm did not match 85.

The min score matched was `r matchedDatamin2` and the max score matched was `r matchedDatamax2`.

```{r matchedPlot2}

ggplot(matchedData2, aes(x = distance, fill = as.factor(treatment))) +
 geom_histogram(position = 'identity') +
  facet_grid(rows = vars(treatment)) +
  theme_classic()


```

Both R and SAS provide a report on how the matched data looks relative to the unmatched data in terms of all the variables in respect to mean difference.  The major differences (change of 10% standard mean difference) between the two caliper inputs occur at the sex, CHF and DIAB.  The 0.01 caliber pushed the standard mean difference ~30% worse.  The CHF also got ~20% worse.  The DIAB did get better by ~11%.

Based upon the mean percent change seen between the two calipers, I think I would prefer to use the looser caliper in this example.  While the tigher caliper selected less pairs, it would seem like the mean difference in those pairs actual got worse.  In reality, these differences may not actually impact my final results but still, I would select the caliper that lead to more closely paired results.
