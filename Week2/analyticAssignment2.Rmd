---
title: "Week 2 Analytical Assigment"
author: "M. Onimus"
date: "03/17/2020"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapse: yes
      smooth_scrolling: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(haven)
library(car)
library(broom)
library(oddsratio)
library(jtools)
library(kableExtra)
library(tidymodels)
```

# R Set up

Before getting started, I have loaded in a few packages to help us with the analysis.

-   `tidyverse`: A collection of r packages used to make data import, manipulation, and analysis easier.
-   `here`: A package that makes it easier to navigate around the folder structure.
-   `haven`: A package with a set of functions for reading in SAS files.
-   `car`: A package the provides Applied Regression methods.
-   `broom`: A package used for building and cleaning up models built in R.
-   `jtools`: A package for making publication ready tables.
-   `kableExtra`: A package for printing pretty tables to html.
-   `oddsratio`: A package that provides a calculation for odds ratio based upon data and a model.
-   `tidymodels`: A collection of model building packages that play very nicely in the tidyverse

# From the Assignment

## First Part

You will be using SAS and the data set health.sas7bdat for this assignment. This is a cross-sectional data set of patients discharged from a hospital in 2019. The primary outcome variable is whether or not they had a Primary Care Physician (PCP) follow-up visit within 5 days of their discharge from the hospital (PCP\_visit; 1 = had a visit, 0 = did not have a visit). You will be conducting one basic logistic regression analysis with 3 covariates, that has already been specified and coded, and interpreting the results. You can use the examples from the lecture to guide you in your interpretation.

## Second Part

Next, you will expand on this basic model by including other covariates that should provide even more insight into the differences between those who had a PCP visit and those who did not. The purpose of this part of the assignment is not to come up with the "right" answer but rather to demonstrate you understand the process of testing and comparing different models and coming to some conclusion that describes the differences between people who go to follow-up visits and those who do not.

## Overview of the Data

The data set health.sas7bdat is a cross-sectional data set of patients discharged from a hospital in 2019. with the following columns: 

-   subject: observation identifier 
-   PCP_visit: had a PCP visit within 5 days of hospital discharge (1=had a visit, 0=did not have a visit) 
-   SEX: (1=male; 0=female) 
-   AGE: patient age in years 
-   urban_rural: live in an urban or non-urban (rural, or suburban) zipcode 
-   unemp_rate: unemployment rate in the subject's zip code 
-   comorbidity_score: general score of disease states - higher scores indicate higher illness burden 
-   ALZ: had diagnosis of Alzheimer's (yes=1, no=0) 
-   AST: had diagnosis of asthma (yes=1, no=0) 
-   CAD: had diagnosis of coronary artery disease (yes=1, no=0) 
-   CHF: had diagnosis of congestive heart failure (yes=1, no=0) 
-   COPD: had diagnosis of chronic obstructive pulmonary disease (yes=1, no=0) 
-   DIAB: had diagnosis of diabetes (yes=1, no=0) 
-   HTN: had diagnosis of hypertension (yes=1, no=0) 
-   OSTEO: had diagnosis of osteoarthritis (yes=1, no=0)

# Assignment

## Read the data in

In order to read the data into R, we will need to use the `haven` package.

```{r readData}

data <- read_sas(here("data/health.sas7bdat")) %>% 
  mutate(PCP_visit = as.factor(PCP_visit),
         SEX = as.factor(SEX),
         urban_rural = as.factor(urban_rural))


```

Sometimes when you read in SAS data, you get additional column name attributes, for this data, you do not.

This data set contains `r NROW(data)` rows with `r NCOL(data)` variables, as described in the data overview.

## First Part - Basic Logistic Regression

### Questions 1-4

Using the variable PCP\_visit as the outcome variable run a logistic regression model using AGE, SEX, and urban\_rural to predict the likelihood that a patient had a follow-up visit with his/her PCP within 5 days of being discharged from the hospital.

If you open up the code block, you will see the formula is similar to SAS. The anova code call is slightly different, SAS defaults to using type 3 while R defaults to 1. We just need to tell R explicit which type we want as well as which test ("Wald").

```{r basicLog, cache=TRUE}

model <- glm(PCP_visit ~ AGE + SEX + urban_rural ,family=binomial(link='logit'), data=data)

mod1 <- summary(model)

anov1 <- car::Anova(model, type = 3, test = "Wald")

```

Here is the summary of the model:

```{r modSum, echo=FALSE}

jtools::summ(model)

```

Here is a summary of the anova chi-sq fit:

```{r anoSum, echo=FALSE}

options(knitr.kable.NA = '') # suppress showing NA values in table
kable(anov1, format = "html",  
      caption = "Analysis of Deviance Table (Type III tests)\nResponse: PCP_visit\n",
      digits = c(3, 2, 6), align = "rrr")  %>%
  kable_styling(position = "left")


```

The Wald chi-square results for age and urban\_rule were `r anov1$Chisq[[2]]` and `r anov1$Chisq[[4]]`, respectively. These large Wald chi-square results indicate that the estimate is significantly different from 0 and therefore statistically significant, p-values \< 2e-16. The Wald chi-square result for sex was `r anov1$Chisq[[3]]` and while different from 0 and still statistically different, p-value `r round(anov1[[3]][[3]], 8)`.

```{r odds1}

odds <- oddsratio::or_glm(data, model, incr = list(AGE = 1))

```

The odds ratio output from R is slightly different than SAS for the AGE predictor (R: 1.006 vs SAS: 0.994).  I did not attempt to find out why this difference exists, it may be due to how R increments the `or_glm` function.

```{r odds, echo=FALSE}

options(knitr.kable.NA = '') # suppress showing NA values in table
kable(odds, format = "html",  
      caption = "Odds Ratio",
      digits = c(0, 4, 4, 4), align = "rrrr")  %>%
  kable_styling(position = "left")


```

The age and sex odds ratio are very close to 1 regardless of program, indicating that the outcome is as likely to occur as it is not to occur.  The urban_rural is less than 1 indicting the odds decrease based on this variable.

Based upon the data, it would seem like you are more likely to have a PCP visit based on your age and where you live.  If you think about the question more broadly and without data, this would fall in line with my hypothesis.  It makes sense that the more rural areas would have a more difficult time having a following up visit, I imagine most people would not be inclined to drive a long distance to their PCP after being discharged from the hospital.  The age population is skewed towards the older, it would also make sense since they have a more difficult time getting to the PCP office.  


```{r plot1}

ggplot(data, aes(x = AGE)) +
  geom_histogram(binwidth = 5) +
  theme_classic() +
  scale_x_continuous(breaks = c(10,20,30,40,50,60,70,80,90,100)) +
  labs(
    title = "Age Distrubtion in the Dataset",
    subtitle = "Binwidth set to increments of 5"
  )


```

## Second Part - Choose Your Own Adventure

### Question 5

I will be using a combination of packages from the `tidymodels` to build a number of different logistic models for the data.  From the original data set, I am going to remove the subject variable first.  I am also going to make an age bucket in 10 year increments, 0-10 = 1, 11-20 = 2, etc.

I will also make a training and test data set so we can measure how well our models are doing at predicting the outcome (PCP_visit).  Last, I will set up a small recipe which will be used in future modeling calls.  This call will have all the variables but I will have the option to select/remove some as we continue to build our model.

```{r dataPrep}

dataToModelWith <- data %>% 
  select(-subject) %>% 
  mutate(ageBuckets = floor(AGE/10)) %>% 
  select(-AGE)

set.seed(2)

dataSplit <- initial_split(dataToModelWith, prop = 3/4)

trainData <- training(dataSplit)
testData <- testing(dataSplit)


```


The first one below is just a blanket logistic model using all the variables as is.  We will be using the `tidymodels` workflow.  This involves building a recipe (the formula for fit), coding our model choice (glm), and finally fitting the data and viewing the results.


```{r modelBuilding}

rec <- recipe(PCP_visit ~ ., data = trainData)

lrModel <- logistic_reg() %>% 
  set_engine('glm') %>% 
  set_mode('classification')


modelWF <- workflow() %>% 
  add_model(lrModel) %>% 
  add_recipe(rec)

modelFit <- modelWF %>% 
  fit(data = trainData)


modelFit %>% 
  pull_workflow_fit() %>% 
  tidy() %>% 
  kable(., format = 'html',
        caption = "First Model Anova Table") %>% 
  kable_styling(position = 'left')
  

```

Now that we have our model built, we can see how well we can predict on that test set we created a few sections ago.  I will be showing a probability model.   

```{r allVariableFit}

mod1Fit <- predict(modelFit, testData) %>% 
  bind_cols(testData %>% select(PCP_visit))

kable(table(mod1Fit),
      caption = "First Model Confusion Matrix") %>% 
  kable_paper() %>% 
  add_header_above(c(" ", "Actual PCP_visit Result" = 2)) %>% 
  pack_rows("Predicted Result",1,2) %>% 
  kable_styling(position = 'left')
  

```

Based on this model, it would seem like we can predict a PCP_visit = 0 accurately about 99.79% of the time and a PCP_visit = 1 only about 0.2% of the time.


Next, we will start to remove some variables and see if the model can get any better.  I am going to start by removing SEX and ALZ as those are not significant at 0.01.  I will keep removing variables that pop up as not significant.

```{r glm}

updateRec <- rec %>% 
  update_role(c(SEX, ALZ), new_role = "ID")

model2WF <- workflow() %>% 
  add_model(lrModel) %>% 
  add_recipe(updateRec)

modelFit2 <- model2WF %>% 
  fit(data = trainData)

# modelFit2 %>% 
#   pull_workflow_fit() %>% 
#   tidy() %>% 
#   kable(., format = 'html') %>% 
#   kable_styling(position = 'left')


updateRec2 <- updateRec %>% 
  update_role(OSTEO, new_role = "ID")

model3WF <- workflow() %>% 
  add_model(lrModel) %>% 
  add_recipe(updateRec2)

modelFit3 <- model3WF %>% 
  fit(data = trainData)

modelFit3 %>% 
  pull_workflow_fit() %>% 
  tidy() %>% 
  kable(., format = 'html',
        caption = "Second Model Anova Table") %>% 
  kable_styling(position = 'left')


```


So I ended up removing 3 variables (SEX, ALZ, and OSTEO), we will now predict on the test data and see how the model looks now.

```{r fit2}

mod3Fit <- predict(modelFit3, testData) %>% 
  bind_cols(testData %>% select(PCP_visit))

kable(table(mod3Fit),
      caption = "Second Model Confusion Matrix") %>% 
  kable_paper() %>% 
  add_header_above(c(" ", "Actual PCP_visit Result" = 2)) %>% 
  pack_rows("Predicted Result",1,2) %>% 
  kable_styling(position = 'left')




```

Based on this variable reduced model, it would seem like we can predict a PCP_visit = 0 accurately about 99.79% of the time and a PCP_visit = 1 only about 0.3% of the time, so just a touch better than the first model.

The last model I am going to generate is just looking at the conditions to see if that provides up a better predictor.

```{r mod4}

updateRec4 <- rec %>% 
  update_role(c(SEX, urban_rural, unemp_rate, comorbidity_score, ageBuckets), new_role = "ID")

model4WF <- workflow() %>% 
  add_model(lrModel) %>% 
  add_recipe(updateRec4)

modelFit4 <- model4WF %>% 
  fit(data = trainData)

modelFit4 %>% 
  pull_workflow_fit() %>% 
  tidy() %>% 
  kable(., format = 'html',
        caption = "Third Model Anova Table") %>% 
  kable_styling(position = 'left')


```

I ended up with 8 predictors with 5 having a significant p-value.

```{r mod4Table}

mod4Fit <- predict(modelFit4, testData) %>% 
  bind_cols(testData %>% select(PCP_visit))

kable(table(mod4Fit),
      caption = "Third Model Confusion Matrix") %>% 
  kable_paper() %>% 
  add_header_above(c(" ", "Actual PCP_visit Result" = 2)) %>% 
  pack_rows("Predicted Result",1,2) %>% 
  kable_styling(position = 'left')


```

Well I was able to successfully predict a single correct PCP_visit = 1.  Definitely not the best model I made.

The best one I created was the second model but even that was not really that great.


Finally, I am going to just explore the data by generating some plots.

```{r plots1, fig.cap = "Histogram of Age Filled by PCP_visit"}

ggplot(data, aes(x = AGE, fill = PCP_visit)) + 
  geom_histogram(binwidth = 5, alpha = 0.5) +
  scale_x_continuous(breaks = c(10,20,30,40,50,60,70,80,90,100)) +
  theme_classic() +
  labs(
    title = "Histogram By Age Filled by PCP_visit"
  )


```

Figure 1 shows the general shape of PCP_visit is the same across the entire age spectrum.  I expected that elderly or the very young to be more likely to have a follow-up appointment.  

```{r plots2, fig.cap = "Histogram of Age Filled by PCP_visit and Facet by Sex"}

ggplot(data, aes(x = AGE, fill = PCP_visit)) + 
  geom_histogram(binwidth = 5, alpha = 0.5) +
  scale_x_continuous(breaks = c(10,20,30,40,50,60,70,80,90,100)) +
  theme_classic() +
  labs(
    title = "Histogram By Age Filled by PCP_visit and Faceted by Sex"
  ) +
  facet_wrap(~SEX)


```

Figure 2 shows the general shape of PCP_visit is the same across the entire age spectrum with the addition of sex as a facet.  Once again, we see the same trends regardless of sex.

```{r plots3, fig.cap = "Histogram of Age Filled by PCP_visit and Facet by Urban"}

ggplot(data, aes(x = AGE, fill = PCP_visit)) + 
  geom_histogram(binwidth = 5, alpha = 0.5) +
  scale_x_continuous(breaks = c(10,20,30,40,50,60,70,80,90,100)) +
  theme_classic() +
  labs(
    title = "Histogram By Age Filled by PCP_visit and Faceted by Urban"
  ) +
  facet_wrap(~urban_rural)


```

Figure 3 is where we see the largest difference so far, urban = 0 is far more likely to have a PCP_visit = 0 compared to urban = 0.  It is important to note that the of data with urban = 1 is significantly less than urban = 0.

```{r plots4, fig.cap = "Column Plot of Diag vs Count Filled by PCP_visit"}

dataMorb <- dataToModelWith %>% 
  select(PCP_visit, ALZ, AST, CAD, CHF, COPD, DIAB, HTN, OSTEO) %>% 
  pivot_longer(!PCP_visit, names_to = "diag", values_to = 'value') %>% 
  group_by(PCP_visit, diag) %>% 
  summarise(count = sum(value))


ggplot(dataMorb, aes(x = diag, y = count, fill = PCP_visit)) + 
  geom_col(position = 'dodge', alpha = 0.5) +
  theme_classic() +
  labs(
    title = "Column Plot of Diag vs Count Filled by PCP_visit"
  )


```

I know I should not be surprised based upon how well all my models performed but I still find it shocking the number of people with pre existing conditions that do not have a PCP visit.